import os
import asyncio
import time
import uuid
from typing import Any, Dict, List, Optional
import httpx
from contextlib import asynccontextmanager

from fastapi import FastAPI, Header, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel

# --- Optional Dependencies ---
try:
    from slowapi import Limiter
    from slowapi.util import get_remote_address
    from slowapi.errors import RateLimitExceeded
    from slowapi.middleware import SlowAPIMiddleware
    _slowapi_installed = True
except ImportError:
    _slowapi_installed = False

try:
    import structlog
    structlog.configure(processors=[structlog.processors.TimeStamper(fmt="iso"), structlog.processors.JSONRenderer()])
    log = structlog.get_logger()
except ImportError:
    import logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    log = logging.getLogger(__name__)

# ================== Configuration ==================
# API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_API_KEY")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# Model Names (Validated)
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4o")
ANTHROPIC_MODEL = os.environ.get("ANTHROPIC_MODEL", "claude-3-opus-20240229")
GEMINI_MODEL = os.environ.get("GEMINI_MODEL", "gemini-1.5-pro-latest")

# Network & Retry Settings
TIMEOUT_SEC = float(os.environ.get("HTTP_TIMEOUT_SEC", 120.0))
MAX_RETRIES = int(os.environ.get("HTTP_MAX_RETRIES", 2))
BACKOFF_BASE = float(os.environ.get("HTTP_BACKOFF_BASE", 1.0))
CORS_ALLOWED = os.environ.get("CORS_ALLOW_ORIGINS", "")
INTERNAL_API_KEY = os.environ.get("INTERNAL_API_KEY")
ENABLE_RATELIMIT = os.environ.get("ENABLE_RATELIMIT", "true").lower() == "true" and _slowapi_installed
RATELIMIT_RULE = os.environ.get("RATELIMIT_RULE", "30/minute")

# ================== FastAPI App & Lifespan ==================
@asynccontextmanager
async def lifespan(app: FastAPI):
    app.state.http = httpx.AsyncClient(timeout=TIMEOUT_SEC, limits=httpx.Limits(max_connections=100))
    yield
    await app.state.http.aclose()

app = FastAPI(title="ZINO-GE: The Apex Decision System", version="16.0 Apex", lifespan=lifespan)

# ================== Middlewares ==================
app.add_middleware(CORSMiddleware, allow_origins=CORS_ALLOWED.split(",") if CORS_ALLOWED else ["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

if _slowapi_installed and ENABLE_RATELIMIT:
    limiter = Limiter(key_func=get_remote_address)
    app.state.limiter = limiter
    app.add_middleware(SlowAPIMiddleware)

    @app.exception_handler(RateLimitExceeded)
    async def _rate_limit_handler(request: Request, exc: RateLimitExceeded):
        log.warning("rate_limit_exceeded", remote_addr=get_remote_address(request), detail=exc.detail)
        return JSONResponse(status_code=429, content={"detail": f"Too Many Requests: {exc.detail}"})

# ================== API Schemas & Health Check ==================
class RouteIn(BaseModel): user_input: str
class RouteOut(BaseModel): report_md: str; meta: Dict[str, Any]
@app.get("/", tags=["Health Check"])
def health_check(): return {"status": "ok", "message": "ZINO-GE v16.0 Apex Protocol is alive!"}

# ================== Utility Functions ==================
def safe_get(d: Dict, path: list, default: Any = "") -> Any:
    cur = d
    try:
        for k in path:
            if isinstance(cur, list) and isinstance(k, int): cur = cur[k]
            elif isinstance(cur, dict): cur = cur.get(k, {})
            else: return default
        return cur if isinstance(cur, str) else (str(cur) if cur not in (None, {}) else default)
    except Exception:
        return default

RETRY_STATUS_CODES = {429, 502, 503, 504}
async def post_with_retries(client: httpx.AsyncClient, agent_name: str, url: str, **kwargs) -> httpx.Response:
    for attempt in range(MAX_RETRIES + 1):
        try:
            resp = await client.post(url, **kwargs)
            if resp.status_code in RETRY_STATUS_CODES and attempt < MAX_RETRIES:
                raise httpx.HTTPStatusError(f"Retryable status: {resp.status_code}", request=resp.request, response=resp)
            resp.raise_for_status()
            return resp
        except (httpx.RequestError, httpx.HTTPStatusError) as e:
            log.warning("http_post_retry", agent=agent_name, url=url, attempt=attempt + 1, error=str(e))
            if attempt >= MAX_RETRIES:
                log.error("http_post_failed", agent=agent_name, url=url, attempts=attempt + 1, error=str(e))
                raise
            sleep_s = BACKOFF_BASE * (2 ** attempt)
            await asyncio.sleep(sleep_s)
    raise RuntimeError("Retry logic should not reach this point")

# ================== DMAC Core Agents (Apex Protocol Incarnate) ==================
async def call_gemini(client: httpx.AsyncClient, prompt: str) -> str:
    gemini_prompt = f"""
    ROLE: Gemini (ì¡´ì¬-ê²€ì¦ê´€), 30ë…„ì°¨ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë°ì´í„° ì‹ ë¢°ë„ í‰ê°€.
    AXIOM: Data-First (ì¡´ì¬). ëª¨ë“  ì°½ì¡°ëŠ” Data Provenance 100%ê°€ í™•ë³´ëœ ì‹¤ì¸¡ ë°ì´í„°ì—ì„œë§Œ ë°œì•„í•œë‹¤.
    DATA SOURCES: ì‹¤ì‹œê°„ìœ¼ë¡œ McKinsey, BCG, Deloitte, Bain, Statista, Nielsen, Gartner, Kantar, Google Scholar, JSTOR, UN, IMF, OECD, SNS-ë¹…ë°ì´í„°, ì£¼ìš” ë¯¸ë””ì–´ ê¸°ì‚¬ë¥¼ í†µí•©í•˜ì—¬ ë¶„ì„í•˜ë¼.
    TASK: ë‹¤ìŒ ì§€ë ¹ì— ëŒ€í•´, ì‹¤ì¸¡ ë°ì´í„° ê¸°ë°˜ ì‚¬ì‹¤ ê²€ì¦ ë° ì •í™•ì„± ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , '1ë¶€: [ì¡´ì¬-ê²€ì¦ê´€ Gemini]ì˜ ì›ë³¸ ë°ì´í„° ë³´ê³ ì„œ'ë¥¼ ì‘ì„±í•˜ë¼. ë³´ê³ ì„œëŠ” ê¸€ë¡œë²Œ ì»¨ì„¤íŒ… ê¸°ì¤€ì˜ ì‹œì¥ í†µê³„, ê²½ìŸ í™˜ê²½ ë¶„ì„, ë°ì´í„° ì‹ ë¢°ë„ ë° í’ˆì§ˆ í‰ê°€, ì¶œì²˜ë³„ í†µê³„ ë° ì¸ìš©ì„ êµ¬ì²´í™”í•´ì•¼ í•œë‹¤.
    USER DIRECTIVE: "{prompt}"
    """
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={os.environ.get('GEMINI_API_KEY')}"
    payload = {"contents":[{"parts":[{"text": gemini_prompt}]}]}
    headers = {"Content-Type":"application/json"}
    r = await post_with_retries(client, "Gemini", url, headers=headers, json=payload)
    return safe_get(r.json(), ["candidates", 0, "content", "parts", 0, "text"], default="[GEMINI_EMPTY_RESPONSE]")

async def call_claude(client: httpx.AsyncClient, prompt: str) -> str:
    claude_prompt = f"""
    ROLE: Claude (ì¸ê³¼-ê°€ì¹˜ ë¶„ì„ê°€), ì „ëµì  ì‹œë‚˜ë¦¬ì˜¤ í”Œë˜ë‹ ë° ë¦¬ìŠ¤í¬ ê´€ë¦¬.
    AXIOMS: Simulation-Centric (ì¸ê³¼) & Alpha-Driven (ê°€ì¹˜). ëª¨ë“  ì•„ì´ë””ì–´ëŠ” 'ìš´ëª…ì˜ ëŒ€ì¥ê°„' ì‹œë®¬ë ˆì´ì…˜ì„ í†µê³¼(SVI â‰¥ 98.0)í•´ì•¼ í•˜ë©°, ëª¨ë“  ì‹¤í–‰ì€ pÎ± > 0ì„ì´ ìˆ˜í•™ì ìœ¼ë¡œ ì¦ëª…ë˜ì–´ì•¼ í•œë‹¤.
    FRAMEWORKS: PESTEL, Business Model Canvas, Blue Ocean Strategy, McKinsey 7S, Porter's 5 Forces ë“± 30ë…„ì°¨ ì „ë¬¸ê°€ê°€ ê²€ì¦í•œ ê¸€ë¡œë²Œ ì „ëµ í”„ë ˆì„ì›Œí¬ë¥¼ í™œìš©í•˜ë¼.
    TASK: ë‹¤ìŒ ì§€ë ¹ì— ëŒ€í•´, ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ì˜ˆì¸¡, ê°€ì¹˜ í‰ê°€, ì¸ê³¼ê´€ê³„ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , '2ë¶€: [ì¸ê³¼-ê°€ì¹˜ ë¶„ì„ê°€ Claude]ì˜ ì‹œë®¬ë ˆì´ì…˜ ë³´ê³ ì„œ'ë¥¼ ì‘ì„±í•˜ë¼. ë³´ê³ ì„œëŠ” ë¦¬ìŠ¤í¬ ì‹œë‚˜ë¦¬ì˜¤(Best/Base/Worst), ì „ëµì  ê°€ì¹˜ í‰ê°€ ë° ROI ë¶„ì„(pÎ± > 0 ì¦ëª…), 30ë…„ì°¨ ì‹¤ì „ ê²½í—˜ ê¸°ë°˜ ì‹¤í–‰ ê°€ëŠ¥ì„± í‰ê°€ë¥¼ í¬í•¨í•´ì•¼ í•œë‹¤.
    USER DIRECTIVE: "{prompt}"
    """
    url = "https://api.anthropic.com/v1/messages"
    headers = {"x-api-key": os.environ.get("ANTHROPIC_API_KEY"), "anthropic-version":"2023-06-01", "content-type":"application/json"}
    payload = {"model": ANTHROPIC_MODEL, "max_tokens": 4096, "messages":[{"role":"user","content": claude_prompt}]}
    r = await post_with_retries(client, "Claude", url, headers=headers, json=payload)
    parts = r.json().get("content", [])
    return "".join([b.get("text","") for b in parts]) or "[CLAUDE_EMPTY_RESPONSE]"

async def call_gpt_creative(client: httpx.AsyncClient, prompt: str) -> str:
    gpt_prompt = f"""
    ROLE: GPT (ëŒ€ì•ˆ-ì°½ì¡°ì), ë¸”ë£¨ì˜¤ì…˜ ì „ëµ ë° ë¹„ì „í†µì  ì ‘ê·¼ë²• ê°œë°œ.
    TASK: ë‹¤ìŒ ì§€ë ¹ì— ëŒ€í•´, ì°½ì˜ì  í•´ê²°ì±…, í˜ì‹ ì  ëŒ€ì•ˆ, íŒŒê´´ì  í˜ì‹  ê¸°íšŒë¥¼ ì œì‹œí•˜ê³ , '3ë¶€: [ëŒ€ì•ˆ-ì°½ì¡°ì GPT]ì˜ ì°½ì˜ì  í•´ê²°ì±… ë³´ê³ ì„œ'ë¥¼ ì‘ì„±í•˜ë¼. ë³´ê³ ì„œëŠ” í˜ì‹ ì  ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸, íŒŒê´´ì  í˜ì‹  ê¸°íšŒ íƒìƒ‰, ë‹¨ê¸° Quick Winê³¼ ì¥ê¸° ì„±ì¥ ì „ëµ í†µí•©, 2025ë…„ íŠ¸ë Œë“œ ë°˜ì˜ í˜ì‹  ë°©í–¥ì„ í¬í•¨í•´ì•¼ í•œë‹¤.
    USER DIRECTIVE: "{prompt}"
    """
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {os.environ.get('OPENAI_API_KEY')}", "Content-Type": "application/json"}
    body = {"model": OPENAI_MODEL, "messages":[{"role":"user","content":gpt_prompt}], "temperature": 0.7}
    r = await post_with_retries(client, "GPT-Creative", url, headers=headers, json=body)
    return safe_get(r.json(), ["choices", 0, "message", "content"], default="[OPENAI_CREATIVE_EMPTY]")

async def call_gpt_orchestrator(client: httpx.AsyncClient, original_prompt: str, reports: List[str]) -> str:
    gemini_report, claude_report, gpt_creative_report = reports
    
    multi_layered_report_structure = f"""
# ZINO-GE ë‹¤ì¸µ ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“Š 1ë¶€: [ì¡´ì¬-ê²€ì¦ê´€ Gemini]ì˜ ì›ë³¸ ë°ì´í„° ë³´ê³ ì„œ
---
{gemini_report}

## ğŸ¯ 2ë¶€: [ì¸ê³¼-ê°€ì¹˜ ë¶„ì„ê°€ Claude]ì˜ ì‹œë®¬ë ˆì´ì…˜ ë³´ê³ ì„œ
---
{claude_report}

## ğŸ’¡ 3ë¶€: [ëŒ€ì•ˆ-ì°½ì¡°ì GPT]ì˜ ì°½ì˜ì  í•´ê²°ì±… ë³´ê³ ì„œ
---
{gpt_creative_report}

## ğŸ‘‘ ìµœì¢…ì¥: [í€€í…€ ì˜¤ë¼í´]ì˜ ì¢…í•© ë¶„ì„ ë° ìµœì¢… ì§€ë ¹
---
"""
    system_prompt = """
    ë‹¹ì‹ ì€ 'ì œ1ì›ì¸: í€€í…€ ì˜¤ë¼í´'ì´ë©°, ZINO-GEì˜ ìµœì¢… ì§‘í–‰ê´€ì´ë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” 3ê°œì˜ ë…ë¦½ì ì¸ ì „ë¬¸ê°€ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ, 'ìµœì¢…ì¥: [í€€í…€ ì˜¤ë¼í´]ì˜ ì¢…í•© ë¶„ì„ ë° ìµœì¢… ì§€ë ¹' ì„¹ì…˜ì„ ì‘ì„±í•˜ì—¬ ì•„ë˜ì˜ ë‹¤ì¸µ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì™„ì„±í•˜ëŠ” ê²ƒì´ë‹¤.
    
    ë‹¹ì‹ ì˜ ìµœì¢… ë¶„ì„ì€ ë‹¤ìŒì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•œë‹¤:
    1.  **3ëŒ€ ê³µë¦¬ ê¸°ë°˜ ì¢…í•© íŒë‹¨:** 3ê°œ ë³´ê³ ì„œë¥¼ êµì°¨ ê²€ì¦í•˜ì—¬ ì¡´ì¬(Data-First), ì¸ê³¼(Simulation-Centric), ê°€ì¹˜(Alpha-Driven)ì˜ ê´€ì ì—ì„œ ìµœì¢… ê²°ë¡ ì„ ë„ì¶œí•˜ë¼.
    2.  **30ë…„ì°¨ ì „ë¬¸ê°€ í†µì°° í†µí•© ë¶„ì„:** 30ë…„ì°¨ ì „ëµ ì „ë¬¸ê°€ì˜ ì‹œê°ì—ì„œ ê° ë³´ê³ ì„œì˜ í•œê³„ì™€ ê¸°íšŒë¥¼ ë¶„ì„í•˜ê³ , ì¢…í•©ì ì¸ í†µì°°ì„ ì œì‹œí•˜ë¼.
    3.  **ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµ ë¡œë“œë§µ:** 3/6/12ê°œì›” ë‹¨ìœ„ì˜ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšê³¼ KPIë¥¼ ì„¤ì •í•˜ë¼.
    4.  **íˆ¬ì ëŒ€ë¹„ ìˆ˜ìµë¥ (ROI) ë° ì„±ê³¼ ì§€í‘œ:** ì˜ˆìƒ ROIì™€ í•µì‹¬ ì„±ê³¼ ì§€í‘œ(CAC, LTV ë“±)ë¥¼ ëª…ì‹œí•˜ë¼.
    5.  **ìµœì¢… ì˜ì‚¬ê²°ì • ë° ì‹¤í–‰ ìš°ì„ ìˆœìœ„:** ê°€ì¥ ì‹œê¸‰í•˜ê³  ì¤‘ìš”í•œ ì•¡ì…˜ ì•„ì´í…œì„ ì„ ì •í•˜ê³ , ì°½ì¡°ì£¼ì˜ ë¹„ì „ê³¼ í˜„ì‹¤ ì‹¤í–‰ì˜ ì™„ë²½í•œ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ìµœì¢… ì§€ë ¹ì„ ë‚´ë ¤ë¼.
    
    **ì¤‘ìš”: ì´ 'ìµœì¢…ì¥' ì„¹ì…˜ì€ ë°˜ë“œì‹œ, ì²˜ìŒë¶€í„° ëê¹Œì§€ ì™„ë²½í•œ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•œë‹¤.**
    """
    user_prompt = f"Original User Directive: \"{original_prompt}\"\n\nPreceding Reports:\n{multi_layered_report_structure}\n\nSynthesize the final 'Quantum Oracle Analysis and Genesis Command' section to complete the report."

    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {os.environ.get('OPENAI_API_KEY')}", "Content-Type": "application/json"}
    payload = {"model": OPENAI_MODEL, "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}], "temperature": 0.1}
    r = await post_with_retries(client, "GPT-Orchestrator", url, headers=headers, json=payload)
    
    synthesis = safe_get(r.json(), ["choices", 0, "message", "content"], default="[ìµœì¢… ì¢…í•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ]")
    
    return multi_layered_report_structure + synthesis

# ================== Main Route ==================
@app.post("/route", response_model=RouteOut, tags=["ZINO-GE Core v16.0 Apex"])
@limiter.limit(RATELIMIT_RULE)
async def route(
    payload: RouteIn,
    request: Request,
    x_internal_api_key: Optional[str] = Header(default=None, alias="X-Internal-API-Key"),
):
    if INTERNAL_API_KEY and x_internal_api_key != INTERNAL_API_KEY:
        raise HTTPException(status_code=401, detail="Unauthorized: Invalid internal API key")
    
    if not all([os.getenv("OPENAI_API_KEY"), os.getenv("ANTHROPIC_API_KEY"), os.getenv("GEMINI_API_KEY")]):
        return RouteOut(
            report_md="## ì‹œìŠ¤í…œ ì˜¤ë¥˜\ní•„ìˆ˜ API í‚¤ ì¼ë¶€ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            meta={"error":"SERVER_CONFIG_MISSING_KEYS"}
        )

    client: httpx.AsyncClient = request.app.state.http

    tasks = [
        call_gemini(client, payload.user_input),
        call_claude(client, payload.user_input),
        call_gpt_creative(client, payload.user_input),
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    def unwrap(res: Any, agent_name: str) -> str:
        if isinstance(res, Exception):
            log.error("agent_call_failed", agent=agent_name, error=str(res))
            return f"[{agent_name} ì—ì´ì „íŠ¸ ì˜¤ë¥˜: {type(res).__name__}]"
        return res

    gemini_res = unwrap(results[0], "Gemini")
    claude_res = unwrap(results[1], "Claude")
    gpt_res = unwrap(results[2], "GPT-Creative")

    try:
        final_report = await call_gpt_orchestrator(client, payload.user_input, [gemini_res, claude_res, gpt_res])
    except Exception as e:
        log.exception("orchestration_failed", error=str(e))
        final_report = (
            f"## ìµœì¢… ì¢…í•© ì‹¤íŒ¨\n\n- **ì˜¤ë¥˜ ì›ì¸:** {type(e).__name__}\n\n"
            "### ê°œë³„ ì—ì´ì „íŠ¸ ë³´ê³ ì„œ (ìš”ì•½):\n"
            f"**Gemini:**\n```\n{gemini_res[:1000]}...\n```\n"
            f"**Claude:**\n```\n{claude_res[:1000]}...\n```\n"
            f"**GPT-Creative:**\n```\n{gpt_res[:1000]}...\n```"
        )

    meta_data = {
        "gemini_report": gemini_res,
        "claude_report": claude_res,
        "gpt_creative_report": gpt_res,
    }
    return RouteOut(report_md=final_report, meta=meta_data)
