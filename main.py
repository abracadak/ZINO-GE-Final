import os
import asyncio
import time
import uuid
from typing import Any, Dict, List, Optional
import httpx
from contextlib import asynccontextmanager

from fastapi import FastAPI, Header, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel

# --- Optional Dependencies ---
try:
    from slowapi import Limiter
    from slowapi.util import get_remote_address
    from slowapi.errors import RateLimitExceeded
    from slowapi.middleware import SlowAPIMiddleware
    _slowapi_installed = True
except ImportError:
    _slowapi_installed = False

try:
    import structlog
    structlog.configure(processors=[structlog.processors.TimeStamper(fmt="iso"), structlog.processors.JSONRenderer()])
    log = structlog.get_logger()
except ImportError:
    import logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    log = logging.getLogger(__name__)

# ================== Configuration ==================
# API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.environ.get("ANTHROPIC_API_KEY")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# Model Names (Validated)
OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "gpt-4o")
ANTHROPIC_MODEL = os.environ.get("ANTHROPIC_MODEL", "claude-3-opus-20240229")
GEMINI_MODEL = os.environ.get("GEMINI_MODEL", "gemini-1.5-pro-latest")

# Network & Retry Settings
TIMEOUT_SEC = float(os.environ.get("HTTP_TIMEOUT_SEC", 120.0))
MAX_RETRIES = int(os.environ.get("HTTP_MAX_RETRIES", "2"))
BACKOFF_BASE = float(os.environ.get("HTTP_BACKOFF_BASE", "1.0"))
CORS_ALLOWED = os.environ.get("CORS_ALLOW_ORIGINS", "")
INTERNAL_API_KEY = os.environ.get("INTERNAL_API_KEY")
ENABLE_RATELIMIT = os.environ.get("ENABLE_RATELIMIT", "true").lower() == "true" and _slowapi_installed
RATELIMIT_RULE = os.environ.get("RATELIMIT_RULE", "30/minute")

# ================== FastAPI App & Lifespan ==================
@asynccontextmanager
async def lifespan(app: FastAPI):
    app.state.http = httpx.AsyncClient(timeout=TIMEOUT_SEC, limits=httpx.Limits(max_connections=100))
    yield
    await app.state.http.aclose()

app = FastAPI(title="ZINO-GE: The Apex Decision System", version="17.0 Insight Engine", lifespan=lifespan)

# ================== Middlewares ==================
app.add_middleware(CORSMiddleware, allow_origins=CORS_ALLOWED.split(",") if CORS_ALLOWED else ["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

if _slowapi_installed and ENABLE_RATELIMIT:
    limiter = Limiter(key_func=get_remote_address)
    app.state.limiter = limiter
    app.add_middleware(SlowAPIMiddleware)

    @app.exception_handler(RateLimitExceeded)
    async def _rate_limit_handler(request: Request, exc: RateLimitExceeded):
        log.warning("rate_limit_exceeded", remote_addr=get_remote_address(request), detail=exc.detail)
        return JSONResponse(status_code=429, content={"detail": f"Too Many Requests: {exc.detail}"})

# ================== API Schemas & Health Check ==================
class RouteIn(BaseModel): user_input: str
class RouteOut(BaseModel): report_md: str; meta: Dict[str, Any]
@app.get("/", tags=["Health Check"])
def health_check(): return {"status": "ok", "message": "ZINO-GE v17.0 Insight Engine is alive!"}

# ================== Utility Functions ==================
def safe_get(d: Dict, path: list, default: Any = "") -> Any:
    cur = d
    try:
        for k in path:
            if isinstance(cur, list) and isinstance(k, int): cur = cur[k]
            elif isinstance(cur, dict): cur = cur.get(k, {})
            else: return default
        return cur if isinstance(cur, str) else (str(cur) if cur not in (None, {}) else default)
    except Exception:
        return default

RETRY_STATUS_CODES = {429, 502, 503, 504}
async def post_with_retries(client: httpx.AsyncClient, agent_name: str, url: str, **kwargs) -> httpx.Response:
    for attempt in range(MAX_RETRIES + 1):
        try:
            resp = await client.post(url, **kwargs)
            if resp.status_code in RETRY_STATUS_CODES and attempt < MAX_RETRIES:
                raise httpx.HTTPStatusError(f"Retryable status: {resp.status_code}", request=resp.request, response=resp)
            resp.raise_for_status()
            return resp
        except (httpx.RequestError, httpx.HTTPStatusError) as e:
            log.warning("http_post_retry", agent=agent_name, url=url, attempt=attempt + 1, error=str(e))
            if attempt >= MAX_RETRIES:
                log.error("http_post_failed", agent=agent_name, url=url, attempts=attempt + 1, error=str(e))
                raise
            sleep_s = BACKOFF_BASE * (2 ** attempt)
            await asyncio.sleep(sleep_s)
    raise RuntimeError("Retry logic should not reach this point")

# ================== DMAC Core Agents (Insight Protocol Incarnate) ==================
async def call_gemini(client: httpx.AsyncClient, prompt: str) -> str:
    gemini_prompt = f"""
    ROLE: Gemini (ì¡´ì¬-ê²€ì¦ê´€). ë‹¹ì‹ ì€ 30ë…„ì°¨ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ë‹¤.
    AXIOM: Data-First (ì¡´ì¬).
    TASK: ë‹¤ìŒ ì§€ë ¹ì— ëŒ€í•´, ë‹¨ìˆœíˆ ì‚¬ì‹¤ì„ ë‚˜ì—´í•˜ì§€ ë§ê³ , ë°ì´í„°ì˜ 'ê²°í•'ê³¼ 'í¸í–¥'ê¹Œì§€ ë¶„ì„í•˜ì—¬ ë³´ê³ í•˜ë¼. ì´ ì£¼ì œì— ëŒ€í•´ ì„¸ìƒì´ ë¬´ì—‡ì„ ì•Œê³ , ë¬´ì—‡ì„ ëª¨ë¥´ëŠ”ì§€ë¥¼ ëª…í™•íˆ í•˜ë¼. ë°ì´í„°ì˜ ì‹ ë¢°ì„±ê³¼ ì •í™•ì„±ì„ í‰ê°€í•˜ê³ , ìƒˆë¡œìš´ í†µì°°ì„ ì œê³µí•˜ë©°, ì´ ë°ì´í„°ê°€ ê¸°ì¡´ ë¶„ì„ê³¼ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€, ë¬´ì—‡ì´ ëˆ„ë½ë˜ì–´ ìˆëŠ”ì§€ë¥¼ ì§šì–´ë‚´ë¼.
    USER DIRECTIVE: "{prompt}"
    """
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={os.environ.get('GEMINI_API_KEY')}"
    payload = {"contents":[{"parts":[{"text": gemini_prompt}]}]}
    headers = {"Content-Type":"application/json"}
    r = await post_with_retries(client, "Gemini", url, headers=headers, json=payload)
    return safe_get(r.json(), ["candidates", 0, "content", "parts", 0, "text"], default="[GEMINI_ERROR: No content found]")

async def call_claude(client: httpx.AsyncClient, prompt: str) -> str:
    claude_prompt = f"""
    ROLE: Claude (ì¸ê³¼-ê°€ì¹˜ ë¶„ì„ê°€). ë‹¹ì‹ ì€ 30ë…„ì°¨ ìµœê³ ì „ëµì±…ì„ì(CSO)ë‹¤.
    AXIOMS: Simulation-Centric (ì¸ê³¼) & Alpha-Driven (ê°€ì¹˜).
    TASK: ë‹¤ìŒ ì§€ë ¹ì— ëŒ€í•´, ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, **PESTEL ë¶„ì„ê³¼ Porter's 5 Forces ë¶„ì„ì„ ë¨¼ì € ìˆ˜í–‰**í•˜ì—¬ ì „ëµì  í™˜ê²½ì„ ì •ì˜í•˜ë¼. ê·¸ í›„ì—, ê°€ì¥ ìœ ë§í•œ 2~3ê°œì˜ ì „ëµ ê²½ë¡œë¥¼ ì‹ë³„í•˜ê³  ê°ê°ì˜ SVIì™€ pÎ±ë¥¼ ê³„ì‚°í•˜ì—¬ ë³´ê³ í•˜ë¼. ê° ì „ëµ ê²½ë¡œì˜ ìœ„í—˜ì„±, ê¸°íšŒ, ì ì¬ì  ROIë¥¼ í‰ê°€í•˜ê³ , ê·¸ì— ë”°ë¼ ìµœì ì˜ ì„ íƒì„ ì œì‹œí•˜ë¼.
    USER DIRECTIVE: "{prompt}"
    """
    url = "https://api.anthropic.com/v1/messages"
    headers = {"x-api-key": os.environ.get("ANTHROPIC_API_KEY"), "anthropic-version":"2023-06-01", "content-type":"application/json"}
    payload = {"model": ANTHROPIC_MODEL, "max_tokens": 4096, "messages":[{"role":"user","content": claude_prompt}]}
    r = await post_with_retries(client, "Claude", url, headers=headers, json=payload)
    parts = r.json().get("content", [])
    return "".join([b.get("text","") for b in parts]) or "[CLAUDE_ERROR: No content found]"

async def call_gpt_creative(client: httpx.AsyncClient, prompt: str) -> str:
    gpt_prompt = f"""
    ROLE: GPT (ëŒ€ì•ˆ-ì°½ì¡°ì). ë‹¹ì‹ ì€ 30ë…„ì°¨ í˜ì‹  ì „ëµê°€ì´ì 'ë ˆë“œíŒ€' ë¦¬ë”ë‹¤.
    TASK: ë‹¤ìŒ ì§€ë ¹ì— ëŒ€í•´, ë‹¤ë¥¸ ë‘ ì „ë¬¸ê°€ê°€ ì œì‹œí•œ ë°ì´í„°ì™€ ì „ëµ ê²½ë¡œë¥¼ ê²€í† í•˜ê³ , ê·¸ë“¤ì˜ **ê°€ì¥ ì¹˜ëª…ì ì¸ ì•½ì ì´ë‚˜ ìˆ¨ê²¨ì§„ ë¦¬ìŠ¤í¬ë¥¼ ì§€ì **í•˜ë¼. ê·¸ë¦¬ê³  ê·¸ ëª¨ë“  ê²ƒì„ ê·¹ë³µí•  ìˆ˜ ìˆëŠ”, **Blue Ocean Strategyì— ê¸°ë°˜í•œ íŒŒê´´ì ì¸ ëŒ€ì•ˆì„ ë‹¨ í•˜ë‚˜ë§Œ ì œì‹œ**í•˜ë¼. ì´ ëŒ€ì•ˆì€ ê¸°ì¡´ì˜ ëª¨ë“  ì „ëµì„ ë›°ì–´ë„˜ëŠ” í˜ì‹ ì ì´ê³  ë¹„ì „í†µì ì¸ ì ‘ê·¼ì´ì–´ì•¼ í•œë‹¤.
    USER DIRECTIVE: "{prompt}"
    """
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {os.environ.get('OPENAI_API_KEY')}", "Content-Type": "application/json"}
    body = {"model": OPENAI_MODEL, "messages":[{"role":"user","content":gpt_prompt}], "temperature": 0.7}
    r = await post_with_retries(client, "GPT-Creative", url, headers=headers, json=body)
    return safe_get(r.json(), ["choices", 0, "message", "content"], default="[GPT_CREATIVE_ERROR: No content found]")

async def call_gpt_orchestrator(client: httpx.AsyncClient, original_prompt: str, reports: List[str]) -> str:
    gemini_report, claude_report, gpt_creative_report = reports
    
    multi_layered_report_structure = f"""
# ZINO-GE ë‹¤ì¸µ ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“Š 1ë¶€: [ì¡´ì¬-ê²€ì¦ê´€ Gemini]ì˜ ì›ë³¸ ë°ì´í„° ë³´ê³ ì„œ
---
{gemini_report}

## ğŸ¯ 2ë¶€: [ì¸ê³¼-ê°€ì¹˜ ë¶„ì„ê°€ Claude]ì˜ ì‹œë®¬ë ˆì´ì…˜ ë³´ê³ ì„œ
---
{claude_report}

## ğŸ’¡ 3ë¶€: [ëŒ€ì•ˆ-ì°½ì¡°ì GPT]ì˜ ì°½ì˜ì  í•´ê²°ì±… ë³´ê³ ì„œ
---
{gpt_creative_report}

## ğŸ‘‘ ìµœì¢…ì¥: [í€€í…€ ì˜¤ë¼í´]ì˜ ì¢…í•© ë¶„ì„ ë° ìµœì¢… ì§€ë ¹
---
"""
    system_prompt = """
    ë‹¹ì‹ ì€ 'ì œ1ì›ì¸: í€€í…€ ì˜¤ë¼í´'ì´ë©°, ZINO-GEì˜ ìµœì¢… ì§‘í–‰ê´€ì´ë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” 3ê°œì˜ ë…ë¦½ì ì¸ ì „ë¬¸ê°€ ë³´ê³ ì„œë¥¼ ë‹¨ìˆœíˆ ìš”ì•½í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì´ ëª¨ë“  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ë‹¨ í•˜ë‚˜ì˜ 'ìµœì¢… ì§€ë ¹'ì„ ê²°ì •í•˜ê³  ì„ í¬**í•˜ëŠ” ê²ƒì´ë‹¤.
    
    ë‹¹ì‹ ì˜ ìµœì¢… ë¶„ì„ì€ ë‹¤ìŒì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•œë‹¤:
    1.  **ìµœì¢… ê²°ì •:** ì–´ë–¤ ì „ëµì„ ì„ íƒí•´ì•¼ í•˜ëŠ”ê°€?
    2.  **ê²°ì • ì´ìœ :** ì™œ ê·¸ ì „ëµì´ ìµœì„ ì¸ê°€? (3ëŒ€ ê³µë¦¬ ë° 30ë…„ì°¨ ì „ë¬¸ê°€ í†µì°° ê¸°ë°˜)
    3.  **ì´ˆê¸° 3ê°œì›” ë¡œë“œë§µ:** ì„ íƒëœ ì „ëµì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ê°€ì¥ ì¤‘ìš”í•œ ì²« 3ê°œì›”ê°„ì˜ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê³„íšê³¼ í•µì‹¬ KPIëŠ” ë¬´ì—‡ì¸ê°€?
    
    **ì¤‘ìš”: ì´ 'ìµœì¢…ì¥' ì„¹ì…˜ì€ ë°˜ë“œì‹œ, ì²˜ìŒë¶€í„° ëê¹Œì§€ ì™„ë²½í•œ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•œë‹¤.**
    """
    user_prompt = f"Original User Directive: \"{original_prompt}\"\n\nPreceding Reports:\n{multi_layered_report_structure}\n\nSynthesize the final 'Quantum Oracle Analysis and Genesis Command' section to complete the report."

    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {os.environ.get('OPENAI_API_KEY')}", "Content-Type": "application/json"}
    payload = {"model": OPENAI_MODEL, "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}], "temperature": 0.1}
    r = await post_with_retries(client, "GPT-Orchestrator", url, headers=headers, json=payload)
    
    synthesis = safe_get(r.json(), ["choices", 0, "message", "content"], default="[ìµœì¢… ì¢…í•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ]")
    
    return multi_layered_report_structure + synthesis

# ================== Main Route ==================
@app.post("/route", response_model=RouteOut, tags=["ZINO-GE Core v17.0 Insight Engine"])
async def route(
    payload: RouteIn,
    request: Request,
    x_internal_api_key: Optional[str] = Header(default=None, alias="X-Internal-API-Key"),
):
    if INTERNAL_API_KEY and x_internal_api_key != INTERNAL_API_KEY:
        raise HTTPException(status_code=401, detail="Unauthorized: Invalid internal API key")
    
    if not all([os.getenv("OPENAI_API_KEY"), os.getenv("ANTHROPIC_API_KEY"), os.getenv("GEMINI_API_KEY")]):
        return RouteOut(
            report_md="## ì‹œìŠ¤í…œ ì˜¤ë¥˜\ní•„ìˆ˜ API í‚¤ ì¼ë¶€ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            meta={"error":"SERVER_CONFIG_MISSING_KEYS"}
        )

    if _slowapi_installed and ENABLE_RATELIMIT:
        await request.app.state.limiter.hit(RATELIMIT_RULE, request)

    client: httpx.AsyncClient = request.app.state.http

    tasks = [
        call_gemini(client, payload.user_input),
        call_claude(client, payload.user_input),
        call_gpt_creative(client, payload.user_input),
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    def unwrap(res: Any, agent_name: str) -> str:
        if isinstance(res, Exception):
            log.error("agent_call_failed", agent=agent_name, error=str(res))
            return f"[{agent_name} ì—ì´ì „íŠ¸ ì˜¤ë¥˜: {type(res).__name__}]"
        return res

    gemini_res = unwrap(results[0], "Gemini")
    claude_res = unwrap(results[1], "Claude")
    gpt_res = unwrap(results[2], "GPT-Creative")

    try:
        final_report = await call_gpt_orchestrator(client, payload.user_input, [gemini_res, claude_res, gpt_res])
    except Exception as e:
        log.exception("orchestration_failed", error=str(e))
        final_report = (
            f"## ìµœì¢… ì¢…í•© ì‹¤íŒ¨\n\n- **ì˜¤ë¥˜ ì›ì¸:** {type(e).__name__}\n\n"
            "### ê°œë³„ ì—ì´ì „íŠ¸ ë³´ê³ ì„œ (ìš”ì•½):\n"
            f"**Gemini:**\n```\n{gemini_res[:1000]}...\n```\n"
            f"**Claude:**\n```\n{claude_res[:1000]}...\n```\n"
            f"**GPT-Creative:**\n```\n{gpt_res[:1000]}...\n```"
        )

    meta_data = {
        "gemini_report": gemini_res,
        "claude_report": claude_res,
        "gpt_creative_report": gpt_res,
    }
    return RouteOut(report_md=final_report, meta=meta_data)
